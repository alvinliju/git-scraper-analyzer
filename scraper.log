Starting to scrape github repos...
Page 1 scraped successfully
Starting to scrape github repos...
Page 2 scraped successfully
Starting to scrape github repos...
Page 3 scraped successfully
Starting to scrape github repos...
Page 4 scraped successfully
Starting to scrape github repos...
Page 5 scraped successfully
Starting to scrape github repos...
Page 6 scraped successfully
Starting to scrape github repos...
Page 7 scraped successfully
Starting to scrape github repos...
Page 8 scraped successfully
Starting to scrape github repos...
Page 9 scraped successfully
Data saved to github_repos
✓ Found 900 repos
Skipping 860 already scraped repos
Traceback (most recent call last):
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/cron_job.py", line 25, in <module>
    asyncio.run(run_scraper())
    ~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 195, in run
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 725, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/cron_job.py", line 17, in run_scraper
    print(f"✓ Scraped {len(details)} repo details")
                       ~~~^^^^^^^^^
TypeError: object of type 'NoneType' has no len()
Starting to scrape github repos...
Traceback (most recent call last):
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
        (self._dns_host, self.port),
    ...<2 lines>...
        socket_options=self.socket_options,
    )
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/urllib3/util/connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py", line 977, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno 8] nodename nor servname provided, or not known

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/urllib3/connectionpool.py", line 488, in _make_request
    raise new_e
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/urllib3/connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
    ~~~~~~~~~~~~~~~~~~~^^^^^^
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/urllib3/connectionpool.py", line 1093, in _validate_conn
    conn.connect()
    ~~~~~~~~~~~~^^
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/urllib3/connection.py", line 753, in connect
    self.sock = sock = self._new_conn()
                       ~~~~~~~~~~~~~~^^
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/urllib3/connection.py", line 205, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x10a7816a0>: Failed to resolve 'api.github.com' ([Errno 8] nodename nor servname provided, or not known)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/requests/adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.github.com', port=443): Max retries exceeded with url: /search/repositories?q=stars:%3E1000&sort=stars&order=desc&per_page=100&page=1 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x10a7816a0>: Failed to resolve 'api.github.com' ([Errno 8] nodename nor servname provided, or not known)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/cron_job.py", line 25, in <module>
    asyncio.run(run_scraper())
    ~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 195, in run
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 725, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/cron_job.py", line 9, in run_scraper
    repos = scrape_all_github_repos()
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/main.py", line 52, in scrape_all_github_repos
    response = scrape_github_repos_with_page(page)
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/main.py", line 36, in scrape_github_repos_with_page
    response = requests.get(url, headers=headers)
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/myenv/lib/python3.13/site-packages/requests/adapters.py", line 677, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.github.com', port=443): Max retries exceeded with url: /search/repositories?q=stars:%3E1000&sort=stars&order=desc&per_page=100&page=1 (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x10a7816a0>: Failed to resolve 'api.github.com' ([Errno 8] nodename nor servname provided, or not known)"))
Starting to scrape github repos...
Page 1 scraped successfully
Starting to scrape github repos...
Page 2 scraped successfully
Starting to scrape github repos...
Page 3 scraped successfully
Starting to scrape github repos...
Page 4 scraped successfully
Starting to scrape github repos...
Page 5 scraped successfully
Starting to scrape github repos...
Page 6 scraped successfully
Starting to scrape github repos...
Page 7 scraped successfully
Starting to scrape github repos...
Page 8 scraped successfully
Starting to scrape github repos...
Page 9 scraped successfully
Data saved to github_repos
✓ Found 900 repos
Skipping 888 already scraped repos
Traceback (most recent call last):
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/cron_job.py", line 25, in <module>
    asyncio.run(run_scraper())
    ~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 195, in run
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 725, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/cron_job.py", line 17, in run_scraper
    print(f"✓ Scraped {len(details)} repo details")
                       ~~~^^^^^^^^^
TypeError: object of type 'NoneType' has no len()
Starting to scrape github repos...
Page 1 scraped successfully
Starting to scrape github repos...
Page 2 scraped successfully
Starting to scrape github repos...
Page 3 scraped successfully
Starting to scrape github repos...
Page 4 scraped successfully
Starting to scrape github repos...
Page 5 scraped successfully
Starting to scrape github repos...
Page 6 scraped successfully
Starting to scrape github repos...
Page 7 scraped successfully
Starting to scrape github repos...
Page 8 scraped successfully
Starting to scrape github repos...
Page 9 scraped successfully
Data saved to github_repos
✓ Found 900 repos
Skipping 0 already scraped repos
Traceback (most recent call last):
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/cron_job.py", line 25, in <module>
    asyncio.run(run_scraper())
    ~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 195, in run
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 725, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/cron_job.py", line 17, in run_scraper
    print(f"✓ Scraped {len(details)} repo details")
                       ~~~^^^^^^^^^
TypeError: object of type 'NoneType' has no len()
Starting to scrape github repos...
Page 1 scraped successfully
Starting to scrape github repos...
Page 2 scraped successfully
Starting to scrape github repos...
Page 3 scraped successfully
Starting to scrape github repos...
Page 4 scraped successfully
Starting to scrape github repos...
Page 5 scraped successfully
Starting to scrape github repos...
Page 6 scraped successfully
Starting to scrape github repos...
Page 7 scraped successfully
Starting to scrape github repos...
Page 8 scraped successfully
Starting to scrape github repos...
Page 9 scraped successfully
Data saved to github_repos
✓ Found 900 repos
Skipping 0 already scraped repos
Traceback (most recent call last):
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/cron_job.py", line 25, in <module>
    asyncio.run(run_scraper())
    ~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 195, in run
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 725, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/cron_job.py", line 17, in run_scraper
    print(f"✓ Scraped {len(details)} repo details")
                       ~~~^^^^^^^^^
TypeError: object of type 'NoneType' has no len()
Starting to scrape github repos...
Page 1 scraped successfully
Starting to scrape github repos...
Page 2 scraped successfully
Starting to scrape github repos...
Page 3 scraped successfully
Starting to scrape github repos...
Page 4 scraped successfully
Starting to scrape github repos...
Page 5 scraped successfully
Starting to scrape github repos...
Page 6 scraped successfully
Starting to scrape github repos...
Page 7 scraped successfully
Starting to scrape github repos...
Page 8 scraped successfully
Starting to scrape github repos...
Page 9 scraped successfully
Data saved to github_repos
✓ Found 900 repos
Skipping 0 already scraped repos
Traceback (most recent call last):
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/cron_job.py", line 25, in <module>
    asyncio.run(run_scraper())
    ~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 195, in run
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 725, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "/Users/l3mon/Documents/finaltryworked/gitscraper/cron_job.py", line 17, in run_scraper
    print(f"✓ Scraped {len(details)} repo details")
                       ~~~^^^^^^^^^
TypeError: object of type 'NoneType' has no len()
